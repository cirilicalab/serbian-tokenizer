# Serbian Tokenizer

Овај репозиторијум садржи библиотеку која имплементира сегментацију текста на српском језику у реченице и речи. Такође, део пројекта је и тест сет, базиран на текстовима објављеним у Политици, на коме су измерене перформанце и упоређене са постојећим токенизаторима у NLTK библиотеци.

## Инсталација

Креирање виртуелног окружења и прављење пакета  
```bash
./build.sh
```

Инсталација пакета
```bash
./install.sh
```

## Како се користи
Из командне линије
```bash
echo "Др. Марко Топаловић је дежурни лекар." | python3 -m srbtok
Др . Марко Топаловић је дежурни лекар .
```

Као Пајтон библиотека
```python
>>> from srbtok import SrbTokenizer
>>> tokenizer = SrbTokenizer()
>>> tokenizer.span_tokenize("Др. Марко Топаловић је дежурни лекар.")
[(0, 2), (2, 3), (4, 9), (10, 19), (20, 22), (23, 30), (31, 36), (36, 37)]
>>> tokenizer.tokenize("Др. Марко Топаловић је дежурни лекар.")
['Др', '.', 'Марко', 'Топаловић', 'је', 'дежурни', 'лекар', '.']
```

## Имплементација
Ова имплементација користи два независна токенизатора:
- Текст прво пролази кроз токенизатор који дели текст на реченице
- Затим за сваку реченицу позивамо токенизатор који дели текст на речи

### Дељење на реченице
Сегментација текста на реченице користи постојећи NLTK PunktTokenizer, који је ретрениран на 1.6 Gb ћириличних текстова политике из 2006-2024. Пошто су сви текстови у сету ћирилични, сегментер вероватно не ради добро на латиници.

### Дељење на речи
Сегментација текста на речи је имплементирана NLTK RegexpTokenizer-ом, за који су ручно имплементирани регуларни изрази за српски језик. Регуларни изрази су исти за ћирилицу и латиницу и ова компонента би требало да ради једнако на оба писма али је тестирана искључиво на ћирилици.

## Експерименти 
Токенизатор је тестиран на тест сет-у који се састоји од 100 насумично изабраних чланака из Политике из 2025 године.

За мерење сам користио само Recall метрику јер су [(Shao et all 2017)](web.archive.org/web/20260105162656/https://aclanthology.org/I17-2015.pdf) показали да је она довољна.

$Recall = TP / RP$

**TP (True Positives)** : број једнаких токена између очекиване токенизације и излаза токенизатора, где је editdistance употребљен за алајмент секвенци.

**RP (Real Positives)** : број токена у очекиваној токенизацији.

Овај начин рачунања је различит од имплементације коју су описали [(Palmer and Burger 1997)](https://web.archive.org/web/20250503031711/https://cdn.aaai.org/Symposia/Spring/1997/SS-97-05/SS97-05-023.pdf) али је имплементација једноставнија и мислим да је такође тачна.

## Резултати

[Резултати су овде](src/experiments/results.md)

